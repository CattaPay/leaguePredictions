{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "## NOTE: this model is gonna be bad... not symmetrical, inputs arbitrarily chosen, not enough training data\n",
    "\n",
    "# reading dat\n",
    "dat = pd.read_csv(\"MLData/combined.csv\")\n",
    "\n",
    "# modifying dat to remove character values\n",
    "dat[\"WinAsInt\"] = dat[\"B_Win\"].transform(lambda x: int(x == \"WIN\"))\n",
    "dat = dat.drop(axis = 1, labels = \"B_Win\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = dat.corr()[\"WinAsInt\"].sort_values(ascending = False)\n",
    "\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinning out dataset\n",
    "print(correlations[correlations < -0.13])\n",
    "print()\n",
    "print(correlations[correlations > 0.13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = correlations[correlations < -0.13].index.to_list() + correlations[correlations > 0.13].index.to_list()\n",
    "training_dat = dat[input_vars]\n",
    "# thinned out dataset actually substantially worse at predicting than the full one is\n",
    "# training_dat = dat\n",
    "print(training_dat)\n",
    "\n",
    "# split test and training data\n",
    "test_dat = training_dat.sample(frac = 0)\n",
    "training_dat = training_dat.drop(test_dat.index)\n",
    "\n",
    "# setting up for xgboost\n",
    "training_label = training_dat[\"WinAsInt\"]\n",
    "training_dat = training_dat.drop(axis = 1, labels = \"WinAsInt\")\n",
    "test_label = test_dat[\"WinAsInt\"]\n",
    "test_dat = test_dat.drop(axis = 1, labels = \"WinAsInt\")\n",
    "\n",
    "dtrain = xgb.DMatrix(data = training_dat, label = training_label)\n",
    "dtest = xgb.DMatrix(data = test_dat, label = test_label)\n",
    "\n",
    "print(training_dat.shape)\n",
    "print(test_dat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 0.1, 'objective': 'binary:logistic'}\n",
    "param['eval_metric'] = 'auc'\n",
    "\n",
    "num_round = 10\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv(\"MLData/LEC_2023_Spring_Test.csv\")\n",
    "teams = prediction_data[[\"B_Team\", \"R_Team\"]]\n",
    "prediction_data = prediction_data.drop(axis = 1, labels = [\"B_Team\", \"R_Team\"])\n",
    "\n",
    "input_vars.remove(\"WinAsInt\")\n",
    "\n",
    "prediction_data = prediction_data[input_vars]\n",
    "\n",
    "dpred = xgb.DMatrix(prediction_data)\n",
    "\n",
    "scores = bst.predict(dpred)\n",
    "teams[\"Small Model Scores (0.13)\"] = scores\n",
    "\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = correlations[correlations < -0.10].index.to_list() + correlations[correlations > 0.10].index.to_list()\n",
    "training_dat = dat[input_vars]\n",
    "# thinned out dataset actually substantially worse at predicting than the full one is\n",
    "# training_dat = dat\n",
    "print(training_dat)\n",
    "\n",
    "# split test and training data\n",
    "test_dat = training_dat.sample(frac = 0)\n",
    "training_dat = training_dat.drop(test_dat.index)\n",
    "\n",
    "# setting up for xgboost\n",
    "training_label = training_dat[\"WinAsInt\"]\n",
    "training_dat = training_dat.drop(axis = 1, labels = \"WinAsInt\")\n",
    "test_label = test_dat[\"WinAsInt\"]\n",
    "test_dat = test_dat.drop(axis = 1, labels = \"WinAsInt\")\n",
    "\n",
    "dtrain = xgb.DMatrix(data = training_dat, label = training_label)\n",
    "dtest = xgb.DMatrix(data = test_dat, label = test_label)\n",
    "\n",
    "print(training_dat.shape)\n",
    "print(test_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 0.1, 'objective': 'binary:logistic'}\n",
    "param['eval_metric'] = 'auc'\n",
    "\n",
    "num_round = 30\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv(\"MLData/LEC_2023_Spring_Test.csv\")\n",
    "# teams = prediction_data[[\"B_Team\", \"R_Team\"]]\n",
    "prediction_data = prediction_data.drop(axis = 1, labels = [\"B_Team\", \"R_Team\"])\n",
    "\n",
    "input_vars.remove(\"WinAsInt\")\n",
    "\n",
    "prediction_data = prediction_data[input_vars]\n",
    "\n",
    "dpred = xgb.DMatrix(prediction_data)\n",
    "\n",
    "scores = bst.predict(dpred)\n",
    "teams[\"Med Model Scores (0.1)\"] = scores\n",
    "\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = dat.columns.to_list()\n",
    "training_dat = dat[input_vars]\n",
    "# thinned out dataset actually substantially worse at predicting than the full one is\n",
    "# training_dat = dat\n",
    "print(training_dat)\n",
    "\n",
    "# split test and training data\n",
    "test_dat = training_dat.sample(frac = 0)\n",
    "training_dat = training_dat.drop(test_dat.index)\n",
    "\n",
    "# setting up for xgboost\n",
    "training_label = training_dat[\"WinAsInt\"]\n",
    "training_dat = training_dat.drop(axis = 1, labels = \"WinAsInt\")\n",
    "test_label = test_dat[\"WinAsInt\"]\n",
    "test_dat = test_dat.drop(axis = 1, labels = \"WinAsInt\")\n",
    "\n",
    "dtrain = xgb.DMatrix(data = training_dat, label = training_label)\n",
    "dtest = xgb.DMatrix(data = test_dat, label = test_label)\n",
    "\n",
    "print(training_dat.shape)\n",
    "print(test_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 2, 'eta': 0.1, 'objective': 'binary:logistic'}\n",
    "param['eval_metric'] = 'auc'\n",
    "\n",
    "num_round = 30\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv(\"MLData/LEC_2023_Spring_Test.csv\")\n",
    "# teams = prediction_data[[\"B_Team\", \"R_Team\"]]\n",
    "prediction_data = prediction_data.drop(axis = 1, labels = [\"B_Team\", \"R_Team\"])\n",
    "\n",
    "input_vars.remove(\"WinAsInt\")\n",
    "\n",
    "prediction_data = prediction_data[input_vars]\n",
    "\n",
    "dpred = xgb.DMatrix(prediction_data)\n",
    "\n",
    "scores = bst.predict(dpred)\n",
    "teams[\"Full Model Scores\"] = scores\n",
    "\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.to_csv(\"predictions/shitModel.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
